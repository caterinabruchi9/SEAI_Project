{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mcts(mcts_class, env, steps, max_simulations=None, max_rollout_steps=None):\n",
    "    tree = Tree()\n",
    "\n",
    "    # Initialize the MCTS class with additional parameters if provided\n",
    "    mcts = mcts_class(\n",
    "        env=env,\n",
    "        tree=tree,\n",
    "        max_simulations=max_simulations,\n",
    "        max_rollout_steps=max_rollout_steps\n",
    "    )\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    for _ in range(steps):\n",
    "        env.reset()\n",
    "        node = mcts.tree_policy()\n",
    "        reward = mcts.default_policy(node)\n",
    "        mcts.backward(node, reward)\n",
    "        total_reward += reward\n",
    "\n",
    "    avg_reward = total_reward / steps\n",
    "    return avg_reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import sqrt, log\n",
    "import uuid\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "import json\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, state, action, action_space, reward, terminal):\n",
    "        self.identifier = str(uuid.uuid1())\n",
    "        self.parent_identifier = None\n",
    "        self.children_identifiers = []\n",
    "        self.untried_actions = list(range(action_space))\n",
    "        self.state = state\n",
    "        self.total_simulation_reward = 0\n",
    "        self.num_visits = 0\n",
    "        self.performance = 0\n",
    "        self.action = action\n",
    "        self.reward = reward\n",
    "        self.terminal = terminal\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"{}: (action={}, visits={}, reward={:d}, ratio={:0.4f})\".format(\n",
    "                                                  self.state,\n",
    "                                                  self.action,\n",
    "                                                  self.num_visits,\n",
    "                                                  int(self.total_simulation_reward),\n",
    "                                                  self.performance)\n",
    "\n",
    "    def untried_action(self):\n",
    "        action = random.choice(self.untried_actions)\n",
    "        self.untried_actions.remove(action)\n",
    "        return action\n",
    "\n",
    "\n",
    "def vertical_lines(last_node_flags):\n",
    "    vertical_lines = []\n",
    "    vertical_line = '\\u2502'\n",
    "    for last_node_flag in last_node_flags[0:-1]:\n",
    "        if last_node_flag == False:\n",
    "            vertical_lines.append(vertical_line + ' ' * 3)\n",
    "        else:\n",
    "            # space between vertical lines\n",
    "            vertical_lines.append(' ' * 4)\n",
    "    return ''.join(vertical_lines)\n",
    "\n",
    "def horizontal_line(last_node_flags):\n",
    "    horizontal_line = '\\u251c\\u2500\\u2500 '\n",
    "    horizontal_line_end = '\\u2514\\u2500\\u2500 '\n",
    "    if last_node_flags[-1]:\n",
    "        return horizontal_line_end\n",
    "    else:\n",
    "        return horizontal_line\n",
    "\n",
    "class Tree:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nodes = {}\n",
    "        self.root = None\n",
    "\n",
    "    def size(self):\n",
    "        \"\"\"Returns the number of nodes in the tree.\"\"\"\n",
    "        return len(self.nodes)\n",
    "\n",
    "    def depth_info(self):\n",
    "        \"\"\"Calculates the maximum depth and average depth of the tree.\"\"\"\n",
    "        depths = []\n",
    "\n",
    "        def calculate_depth(node, current_depth):\n",
    "            depths.append(current_depth)\n",
    "            for child_id in node.children_identifiers:\n",
    "                calculate_depth(self.nodes[child_id], current_depth + 1)\n",
    "\n",
    "        if self.root is not None:\n",
    "            calculate_depth(self.root, 0)\n",
    "\n",
    "        if depths:\n",
    "            max_depth = max(depths)\n",
    "            avg_depth = sum(depths) / len(depths)\n",
    "            return max_depth, avg_depth\n",
    "        else:\n",
    "            return 0, 0  # In case the tree is empty\n",
    "\n",
    "    def is_expandable(self, node):\n",
    "        if node.terminal:\n",
    "            return False\n",
    "        if len(node.untried_actions) > 0:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def iter(self, identifier, depth, last_node_flags):\n",
    "        if identifier is None:\n",
    "            node = self.root\n",
    "        else:\n",
    "            node = self.nodes[identifier]\n",
    "\n",
    "        if depth == 0:\n",
    "            yield \"\", node\n",
    "        else:\n",
    "            yield vertical_lines(last_node_flags) + horizontal_line(last_node_flags), node\n",
    "\n",
    "        children = [self.nodes[identifier] for identifier in node.children_identifiers]\n",
    "        last_index = len(children) - 1\n",
    "\n",
    "        depth += 1\n",
    "        for index, child in enumerate(children):\n",
    "            last_node_flags.append(index == last_index)\n",
    "            for edge, node in self.iter(child.identifier, depth, last_node_flags):\n",
    "                yield edge, node\n",
    "            last_node_flags.pop()\n",
    "\n",
    "    def add_node(self, node, parent=None):\n",
    "        self.nodes.update({node.identifier: node})\n",
    "\n",
    "        if parent is None:\n",
    "            self.root = node\n",
    "            self.nodes[node.identifier].parent = None\n",
    "        else:\n",
    "            self.nodes[parent.identifier].children_identifiers.append(node.identifier)\n",
    "            self.nodes[node.identifier].parent_identifier=parent.identifier\n",
    "\n",
    "    def children(self, node):\n",
    "        children = []\n",
    "        for identifier in self.nodes[node.identifier].children_identifiers:\n",
    "            children.append(self.nodes[identifier])\n",
    "        return children\n",
    "\n",
    "    def parent(self, node):\n",
    "        parent_identifier = self.nodes[node.identifier].parent_identifier\n",
    "        if parent_identifier is None:\n",
    "            return None\n",
    "        else:\n",
    "            return self.nodes[parent_identifier]\n",
    "\n",
    "    def show(self):\n",
    "        lines = \"\"\n",
    "        for edge, node in self.iter(identifier=None, depth=0, last_node_flags=[]):\n",
    "            lines += \"{}{}\\n\".format(edge, node)\n",
    "        print(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloTreeSearchUCT:\n",
    "    def __init__(self, env, tree, exploration_constant=1.4, max_simulations=1000, max_rollout_steps=50):\n",
    "        self.env = env\n",
    "        self.tree = tree\n",
    "        self.action_space = self.env.action_space.n\n",
    "        self.exploration_constant = exploration_constant\n",
    "        self.max_simulations = max_simulations\n",
    "        self.max_rollout_steps = max_rollout_steps\n",
    "        self.simulation_count = 0\n",
    "        state = self.env.reset()\n",
    "        self.tree.add_node(Node(state=state, action=None, action_space=self.action_space, reward=0, terminal=False))\n",
    "        self.rewards = []\n",
    "\n",
    "    def expand(self, node):\n",
    "        action = node.untried_action()\n",
    "        state, reward, done, _, _ = self.env.step(action)\n",
    "        new_node = Node(state=state, action=action, action_space=self.action_space, reward=reward, terminal=done)\n",
    "        self.tree.add_node(new_node, node)\n",
    "        return new_node\n",
    "\n",
    "    def default_policy(self, node):\n",
    "        if node.terminal:\n",
    "            return node.reward\n",
    "\n",
    "        total_reward = 0\n",
    "        num_steps = 0\n",
    "        while num_steps < self.max_rollout_steps:\n",
    "            action = random.randint(0, self.action_space-1)\n",
    "            state, reward, done, _, _ = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            num_steps += 1\n",
    "            if done:\n",
    "                break\n",
    "        average_reward = total_reward / num_steps if num_steps > 0 else 0\n",
    "        self.rewards.append(average_reward)\n",
    "        return average_reward\n",
    "\n",
    "    def compute_value(self, parent, child):\n",
    "        exploitation_term = child.total_simulation_reward / child.num_visits\n",
    "        exploration_term = self.exploration_constant * sqrt(2 * log(parent.num_visits) / child.num_visits)\n",
    "        return exploitation_term + exploration_term\n",
    "\n",
    "    def best_child(self, node):\n",
    "        best_child = self.tree.children(node)[0]\n",
    "        best_value = self.compute_value(node, best_child)\n",
    "        for child in self.tree.children(node)[1:]:\n",
    "            value = self.compute_value(node, child)\n",
    "            if value > best_value:\n",
    "                best_child = child\n",
    "                best_value = value\n",
    "        return best_child\n",
    "\n",
    "    def tree_policy(self):\n",
    "        node = self.tree.root\n",
    "        while not node.terminal and self.simulation_count < self.max_simulations:\n",
    "            if self.tree.is_expandable(node):\n",
    "                return self.expand(node)\n",
    "            else:\n",
    "                node = self.best_child(node)\n",
    "                state, reward, done, _, _ = self.env.step(node.action)\n",
    "                assert node.state == state\n",
    "        return node\n",
    "\n",
    "    def backward(self, node, value):\n",
    "        while node:\n",
    "            node.num_visits += 1\n",
    "            node.total_simulation_reward += value\n",
    "            node.performance = node.total_simulation_reward / node.num_visits\n",
    "            node = self.tree.parent(node)\n",
    "\n",
    "    def forward(self):\n",
    "        self._forward(self.tree.root)\n",
    "\n",
    "    def _forward(self, node):\n",
    "        best_child = self.best_child(node)\n",
    "        print(\"****** {} ******\".format(best_child.state))\n",
    "\n",
    "        for child in self.tree.children(best_child):\n",
    "            print(\"{}: {:0.4f}\".format(child.state, child.performance))\n",
    "\n",
    "        if len(self.tree.children(best_child)) > 0:\n",
    "            self._forward(best_child)\n",
    "\n",
    "    def render_policy(self, map_size):\n",
    "        \"\"\"\n",
    "        Render the final policy obtained from the MCTS process using the gym's render function.\n",
    "        \"\"\"\n",
    "        node = self.tree.root\n",
    "        path = []\n",
    "        directions = {0: 'Left', 1: 'Down', 2: 'Right', 3: 'Up'}\n",
    "        \n",
    "        print(\"Rendering final policy...\\n\")\n",
    "        \n",
    "        # Close the current environment if open and reset with rendering enabled\n",
    "        self.env.close()\n",
    "        self.env = gym.make('FrozenLake-v1', is_slippery=False, render_mode='human', map_name=map_size)\n",
    "        self.env.reset()\n",
    "\n",
    "        # Traverse the tree to follow the best path\n",
    "        while node and not node.terminal:\n",
    "            self.env.render()\n",
    "            path.append(node.state)\n",
    "            best_child = max(self.tree.children(node), key=lambda n: n.performance, default=None)\n",
    "            if best_child is None:\n",
    "                break\n",
    "            if best_child.action is not None:\n",
    "                print(f\"Action: {directions[best_child.action]} -> State: {best_child.state}\")\n",
    "                self.env.step(best_child.action)  # Take the action in the environment\n",
    "            node = best_child\n",
    "\n",
    "        # Final rendering after reaching the goal\n",
    "        self.env.render()\n",
    "        self.env.close()    \n",
    "        print(f\"\\nFinal policy path (states): {path}\")\n",
    "        \n",
    "        path2 = [item[0] if isinstance(item, tuple) else item for item in path]\n",
    "\n",
    "        print(path2)\n",
    "        return path2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonteCarloTreeSearch:\n",
    "    def __init__(self, env, tree, max_simulations=1000, max_rollout_steps=50):\n",
    "        self.env = env\n",
    "        self.tree = tree\n",
    "        self.action_space = self.env.action_space.n\n",
    "        self.max_simulations = max_simulations\n",
    "        self.max_rollout_steps = max_rollout_steps\n",
    "        self.simulation_count = 0  # Track the number of simulations\n",
    "        state = self.env.reset()\n",
    "        self.tree.add_node(Node(state=state, action=None, action_space=self.action_space, reward=0, terminal=False))\n",
    "\n",
    "    def expand(self, node):\n",
    "        action = node.untried_action()\n",
    "        state, reward, done, _, _ = self.env.step(action)\n",
    "        new_node = Node(state=state, action=action, action_space=self.action_space, reward=reward, terminal=done)\n",
    "        self.tree.add_node(new_node, node)\n",
    "        return new_node\n",
    "\n",
    "    def default_policy(self, node):\n",
    "        if node.terminal:\n",
    "            return node.reward\n",
    "\n",
    "        total_reward = 0\n",
    "        num_steps = 0\n",
    "        while num_steps < self.max_rollout_steps:\n",
    "            action = random.randint(0, self.action_space-1)\n",
    "            state, reward, done, _, _ = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            num_steps += 1\n",
    "            if done:\n",
    "                break\n",
    "        return total_reward\n",
    "\n",
    "    def tree_policy(self):\n",
    "        if self.simulation_count >= self.max_simulations:\n",
    "            return None\n",
    "        \n",
    "        node = self.tree.root\n",
    "        while not node.terminal:\n",
    "            if self.tree.is_expandable(node):\n",
    "                return self.expand(node)\n",
    "            else:\n",
    "                node = random.choice(self.tree.children(node))\n",
    "                state, reward, done, _, _ = self.env.step(node.action)\n",
    "                assert node.state == state\n",
    "        return node\n",
    "\n",
    "    def backward(self, node, value):\n",
    "        while node:\n",
    "            node.num_visits += 1\n",
    "            node.total_simulation_reward += value\n",
    "            node.performance = node.total_simulation_reward / node.num_visits\n",
    "            node = self.tree.parent(node)\n",
    "\n",
    "    def forward(self):\n",
    "        self._forward(self.tree.root)\n",
    "\n",
    "    def _forward(self, node):\n",
    "        best_child = max(self.tree.children(node), key=lambda n: n.performance, default=None)\n",
    "        \n",
    "        print(\"****** {} ******\".format(best_child.state))\n",
    "\n",
    "        for child in self.tree.children(best_child):\n",
    "            print(\"{}: {:0.4f}\".format(child.state, child.performance))\n",
    "\n",
    "        if best_child and len(self.tree.children(best_child)) > 0:\n",
    "            self._forward(best_child)\n",
    "\n",
    "    def render_policy(self):\n",
    "        node = self.tree.root\n",
    "        path = []\n",
    "        directions = {0: 'Left', 1: 'Down', 2: 'Right', 3: 'Up'}\n",
    "        print(\"Rendering final policy...\\n\")\n",
    "        \n",
    "        # Close the current environment if open and reset with rendering enabled\n",
    "        self.env.close()\n",
    "        self.env = gym.make('FrozenLake-v1', is_slippery=True, render_mode='human')\n",
    "        self.env.reset()\n",
    "\n",
    "        while node and not node.terminal:\n",
    "            self.env.render()\n",
    "            path.append(node.state)\n",
    "            children = self.tree.children(node)\n",
    "            \n",
    "            if not children:\n",
    "                print(\"No more actions available.\")\n",
    "                break\n",
    "            \n",
    "            best_child = max(children, key=lambda n: n.performance, default=None)\n",
    "            if best_child is not None and best_child.action is not None:\n",
    "                print(f\"Action: {directions.get(best_child.action, 'Unknown')} -> State: {best_child.state}\")\n",
    "                self.env.step(best_child.action)  # Take the action in the environment\n",
    "                node = best_child\n",
    "            else:\n",
    "                print(\"No best child found.\")\n",
    "                break\n",
    "\n",
    "        # Final rendering after reaching the goal\n",
    "        self.env.render()\n",
    "        self.env.close()    \n",
    "        \n",
    "        path2 = [item[0] if isinstance(item, tuple) else item for item in path]\n",
    "        print(f\"\\nFinal policy path (states): {path2}\")\n",
    "        \n",
    "        return path2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating MCTS with steps: 1000\n",
      "\n",
      "Average reward for MCTS with UCT: 0.00\n",
      "Average reward for traditional MCTS: 0.02\n",
      "\n",
      "Evaluating MCTS with steps: 5000\n",
      "\n",
      "Average reward for MCTS with UCT: 0.17\n",
      "Average reward for traditional MCTS: 0.01\n",
      "\n",
      "Evaluating MCTS with steps: 10000\n",
      "\n",
      "Average reward for MCTS with UCT: 0.56\n",
      "Average reward for traditional MCTS: 0.01\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.envs.registration import register\n",
    "\n",
    "def init_env():\n",
    "    register(\n",
    "        id='FrozenLakeNotSlippery-v0',\n",
    "        entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "        kwargs={'map_name': '4x4', 'is_slippery': False}\n",
    "    )\n",
    "    return gym.make('FrozenLakeNotSlippery-v0')\n",
    "\n",
    "\n",
    "def main():\n",
    "    random.seed(2)\n",
    "    env = init_env()\n",
    "    steps_values = [5000, 10000]  # Example steps values\n",
    "    max_simulations = 100\n",
    "    max_rollout_steps = 10\n",
    "    results = []\n",
    "\n",
    "    for steps in steps_values:\n",
    "        print(f\"\\nEvaluating MCTS with steps: {steps}\\n\")\n",
    "\n",
    "        # Evaluate first implementation\n",
    "        avg_reward_v1 = evaluate_mcts(MonteCarloTreeSearchUCT, env, steps,max_simulations,max_rollout_steps)\n",
    "        print(f\"Average reward for MCTS with UCT: {avg_reward_v1:.2f}\")\n",
    "\n",
    "        # Evaluate second implementation\n",
    "        avg_reward_v2 = evaluate_mcts(MonteCarloTreeSearch, env, steps, max_simulations, max_rollout_steps)\n",
    "        print(f\"Average reward for traditional MCTS: {avg_reward_v2:.2f}\")\n",
    "\n",
    "        # Save the results for this combination\n",
    "        results.append({\n",
    "            'steps': steps,\n",
    "            'avg_reward_v1': avg_reward_v1,\n",
    "            'avg_reward_v2': avg_reward_v2\n",
    "        })\n",
    "\n",
    "    # Save results to a JSON file\n",
    "    with open('simulations/mcts_comparison_results.json', 'w') as json_file:\n",
    "        json.dump(results, json_file, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cidl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
